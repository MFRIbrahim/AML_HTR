\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand*\new@tpo@label[2]{}
\citation{Angelica}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of different levels of difficulty for handwritten text recognition. The upper example shows clear separation and writing of the individual characters while the last one shows connected and overlapping characters that are far away from their standard form.\relax }}{3}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:SampleData}{{1}{3}{Example of different levels of difficulty for handwritten text recognition. The upper example shows clear separation and writing of the individual characters while the last one shows connected and overlapping characters that are far away from their standard form.\relax }{figure.caption.2}{}}
\citation{Goodfellow1}
\citation{Stanford}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory}{4}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Convolutional Neural Networks}{4}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Convolutional Layers}{4}{subsubsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The forward pass of the convolutional layer. On the left is the input with the size 7x7x3. It is padded with a one pixel thick border of zeros. In this graph, the depth dimension or number of channels/filters is depicted by stacking the matrices above one another. In the middle are the two filters applied to the input, in this case we have a filter size of 3x3. This gives us an output of size 3x3x2. The red squares and the black lines show the the entries of the input and the filters applied to those entries to calculate the respective output entry. \relax }}{5}{figure.caption.3}}
\newlabel{fig:Convolution}{{2}{5}{The forward pass of the convolutional layer. On the left is the input with the size 7x7x3. It is padded with a one pixel thick border of zeros. In this graph, the depth dimension or number of channels/filters is depicted by stacking the matrices above one another. In the middle are the two filters applied to the input, in this case we have a filter size of 3x3. This gives us an output of size 3x3x2. The red squares and the black lines show the the entries of the input and the filters applied to those entries to calculate the respective output entry. \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Pooling Layers}{5}{subsubsection.2.1.2}}
\citation{Goodfellow2}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The pooling operation. On the left is one depth slice of an input with width and height equal to 4. The pooling filter in this case has size 2x2 and stride 2 which effectively means that 75\text  {\%} of the image information is discarded.\relax }}{6}{figure.caption.4}}
\newlabel{fig:Pooling}{{3}{6}{The pooling operation. On the left is one depth slice of an input with width and height equal to 4. The pooling filter in this case has size 2x2 and stride 2 which effectively means that 75\text {\%} of the image information is discarded.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Recurrent Neural Networks}{6}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Vanilla RNN}{6}{subsubsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Vanilla RNN visualization. f denotes the non-linear function with parameters W, h is the hidden state, x is the input and y is the output. The upper image is a visualization expressing the feedback nature of the RNN. The lower image elucidates the sequential nature of the RNN by arranging the RNN at different time steps next to itself.\relax }}{7}{figure.caption.5}}
\newlabel{fig:RNNArchitecture}{{4}{7}{Vanilla RNN visualization. f denotes the non-linear function with parameters W, h is the hidden state, x is the input and y is the output. The upper image is a visualization expressing the feedback nature of the RNN. The lower image elucidates the sequential nature of the RNN by arranging the RNN at different time steps next to itself.\relax }{figure.caption.5}{}}
\citation{Olah}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Long-Short-Term-Memory Networks}{8}{subsubsection.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces LSTM Visualization. Hidden state, input and output are shown as before. The purple rectangles are neural network layers that use a sigmoid or tanh function. The brown rectangle and brown circles are point wise operations of multiplication 'X', addition '+' or a tanh function. The dark green circles are the cell state and the red square is the function used to get a desired output like for example a class score.\relax }}{8}{figure.caption.6}}
\newlabel{fig:LSTM}{{5}{8}{LSTM Visualization. Hidden state, input and output are shown as before. The purple rectangles are neural network layers that use a sigmoid or tanh function. The brown rectangle and brown circles are point wise operations of multiplication 'X', addition '+' or a tanh function. The dark green circles are the cell state and the red square is the function used to get a desired output like for example a class score.\relax }{figure.caption.6}{}}
\citation{Hannun}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Connectionist Temporal Classification}{9}{subsection.2.3}}
\newlabel{tab:SampleRNNOutput}{{\caption@xref {tab:SampleRNNOutput}{ on input line 153}}{10}{Connectionist Temporal Classification}{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces RNN output matrix. Only the first four letters and first three time steps are shown. The blank symbol '-' is also part of the output and has a probability for each time step. In this case the text in the input image is likely located near the left border of the image since this example output shows high probability for the respective letters of the word appearing right at the start.\relax }}{10}{table.caption.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Inference}{11}{subsubsection.2.3.1}}
\newlabel{tab:RNNOutputProblem}{{\caption@xref {tab:RNNOutputProblem}{ on input line 179}}{11}{Inference}{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces RNN Output Matrix.\relax }}{11}{table.caption.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Beam Search visualization with a tree graph. The red circles are the candidate extensions and the blue circles are the current guesses. Empty circles stand for empty strings. The dotted lines stand for the output to which the current guess plus the candidate extension map to. In each step we take the 3 most probable extended words. When multiple alignments map to one output (more than 3 circles like in Iteration 2 and 3) the probabilities are summed and summarized under one new guess. \relax }}{12}{figure.caption.9}}
\newlabel{fig:beamsearch}{{6}{12}{Beam Search visualization with a tree graph. The red circles are the candidate extensions and the blue circles are the current guesses. Empty circles stand for empty strings. The dotted lines stand for the output to which the current guess plus the candidate extension map to. In each step we take the 3 most probable extended words. When multiple alignments map to one output (more than 3 circles like in Iteration 2 and 3) the probabilities are summed and summarized under one new guess. \relax }{figure.caption.9}{}}
\citation{IAM}
\citation{Bozinovic}
\citation{Vinciarelli}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{13}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{13}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Example of a transformation of two images. The upper image shows a random erasing of pixels and the lower image shows a perspective shift. Both images were deslanted.\relax }}{13}{figure.caption.10}}
\newlabel{fig:augmentations}{{7}{13}{Example of a transformation of two images. The upper image shows a random erasing of pixels and the lower image shows a perspective shift. Both images were deslanted.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Deslanting}{13}{subsubsection.3.1.1}}
\citation{ScheidlHTR}
\citation{ScheidlCTC}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Metrics}{15}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Word Recognition Model}{16}{subsection.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Neural Network architecture of the base line model.\relax }}{16}{table.caption.11}}
\newlabel{tab:SmallModel}{{3}{16}{Neural Network architecture of the base line model.\relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}CNN}{16}{subsubsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces CNN part of the model. The first cube on the left represents the input of size 1x32x128 (channels x height x width) and the last cube on the right represents the output of size 256x1x32.\relax }}{16}{figure.caption.12}}
\newlabel{fig:ModelCNN}{{8}{16}{CNN part of the model. The first cube on the left represents the input of size 1x32x128 (channels x height x width) and the last cube on the right represents the output of size 256x1x32.\relax }{figure.caption.12}{}}
\citation{ScheidlThesis}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}RNN}{17}{subsubsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Transformation through the model layers. In the top left is the input image and in the bottom left is the RNN output matrix after it was projected onto 80 characters.\relax }}{17}{figure.caption.13}}
\newlabel{fig:featureshapes}{{9}{17}{Transformation through the model layers. In the top left is the input image and in the bottom left is the RNN output matrix after it was projected onto 80 characters.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Text Line Recognition Model}{18}{subsection.3.4}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Example of a Neural Network architecture capable of recognizing text lines.\relax }}{18}{table.caption.14}}
\newlabel{tab:BigModel}{{4}{18}{Example of a Neural Network architecture capable of recognizing text lines.\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{19}{section.4}}
\citation{Bengio}
\citation{LeRoux}
\citation{Delalleau}
\citation{Pascanu1}
\citation{Pascanu2}
\citation{Mikolov}
\citation{Graves}
\citation{ScheidlThesis}
\citation{Moysset}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{20}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Deeper Network}{20}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Deep CNN}{20}{subsubsection.5.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Deep RNN}{20}{subsubsection.5.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Multidimensional LSTM}{20}{subsection.5.2}}
\citation{Bahar}
\citation{Bahar}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Example of a Neural Network architecture with a MDLSTM. Note that the vertical dimension was not reduced to 1 with the CNN layers, rather it was used after the LSTM to calculate an average of the output scores of the LSTM.\relax }}{21}{table.caption.15}}
\newlabel{tab:MDLSTM}{{5}{21}{Example of a Neural Network architecture with a MDLSTM. Note that the vertical dimension was not reduced to 1 with the CNN layers, rather it was used after the LSTM to calculate an average of the output scores of the LSTM.\relax }{table.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A two dimensional LSTM architecture, at each block, the network receives the corresponding pixel from the input image \cite  {Bahar}.\relax }}{22}{figure.caption.16}}
\newlabel{fig:2DLSTM}{{10}{22}{A two dimensional LSTM architecture, at each block, the network receives the corresponding pixel from the input image \cite {Bahar}.\relax }{figure.caption.16}{}}
\bibcite{Angelica}{1}
\bibcite{Goodfellow1}{2}
\bibcite{Stanford}{3}
\bibcite{Goodfellow2}{4}
\bibcite{Olah}{5}
\bibcite{Hannun}{6}
\bibcite{IAM}{7}
\bibcite{ScheidlHTR}{8}
\bibcite{ScheidlCTC}{9}
\bibcite{Bengio}{10}
\bibcite{LeRoux}{11}
\bibcite{Delalleau}{12}
\bibcite{Pascanu1}{13}
\bibcite{Pascanu2}{14}
\bibcite{Mikolov}{15}
\@writefile{toc}{\contentsline {section}{\numberline {6}References}{23}{section.6}}
\bibcite{Graves}{16}
\bibcite{ScheidlThesis}{17}
\bibcite{Moysset}{18}
\bibcite{Bahar}{19}
\bibcite{Vinciarelli}{20}
\bibcite{Bozinovic}{21}
